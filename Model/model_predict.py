#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ¨¡å‹é æ¸¬æ¨¡çµ„ - 2025 ç‰å±±äººå·¥æ™ºæ…§å…¬é–‹æŒ‘æˆ°è³½

æ­¤æ¨¡çµ„è² è²¬ï¼š
1. è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹
2. ç”Ÿæˆé æ¸¬æ©Ÿç‡
3. æ‡‰ç”¨ä¸åŒé–¾å€¼ç”¢ç”ŸäºŒå…ƒé æ¸¬
4. ç”Ÿæˆç¬¦åˆæ¯”è³½æ ¼å¼çš„æäº¤æª”æ¡ˆ
5. æä¾›é–¾å€¼é¸æ“‡å»ºè­°
"""

import numpy as np
import pandas as pd
import joblib
import os
import warnings
warnings.filterwarnings('ignore')

# é è¨­é–¾å€¼è¨­å®š
DEFAULT_THRESHOLDS = [0.30, 0.40, 0.50, 0.60, 0.70]

# é æœŸçš„è­¦ç¤ºå¸³æˆ¶æ¯”ä¾‹ç¯„åœ
EXPECTED_ALERT_RATIO_LOW = 0.5   # 0.5%
EXPECTED_ALERT_RATIO_HIGH = 2.0  # 2.0%

def load_model(model_path='xgboost_model.pkl'):
    """
    è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹
    
    Parameters
    ----------
    model_path : str
        æ¨¡å‹æª”æ¡ˆè·¯å¾‘
    
    Returns
    -------
    object
        è¼‰å…¥çš„æ¨¡å‹ç‰©ä»¶
    """
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼š{model_path}")
    
    print(f"  è¼‰å…¥æ¨¡å‹ï¼š{model_path}")
    model = joblib.load(model_path)
    print("    âœ“ æ¨¡å‹è¼‰å…¥æˆåŠŸ")
    
    return model

def predict_probabilities(model, X_test):
    """
    ç”Ÿæˆé æ¸¬æ©Ÿç‡
    
    Parameters
    ----------
    model : object
        è¨“ç·´å¥½çš„æ¨¡å‹
    X_test : np.ndarray
        æ¸¬è©¦é›†ç‰¹å¾µçŸ©é™£
    
    Returns
    -------
    np.ndarray
        é æ¸¬æ©Ÿç‡ï¼ˆæ­£é¡æ©Ÿç‡ï¼‰
    """
    print("\n  ç”Ÿæˆé æ¸¬æ©Ÿç‡...")
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    
    print(f"    é æ¸¬æ©Ÿç‡åˆ†å¸ƒï¼š")
    print(f"      å¹³å‡ï¼š{y_pred_proba.mean():.4f}")
    print(f"      ä¸­ä½æ•¸ï¼š{np.median(y_pred_proba):.4f}")
    print(f"      æ¨™æº–å·®ï¼š{y_pred_proba.std():.4f}")
    print(f"      æœ€å°å€¼ï¼š{y_pred_proba.min():.4f}")
    print(f"      æœ€å¤§å€¼ï¼š{y_pred_proba.max():.4f}")
    
    # é¡¯ç¤ºæ©Ÿç‡åˆ†ä½æ•¸
    percentiles = [10, 25, 50, 75, 90, 95, 99]
    print(f"\n    æ©Ÿç‡åˆ†ä½æ•¸ï¼š")
    for p in percentiles:
        value = np.percentile(y_pred_proba, p)
        print(f"      {p:2d}%: {value:.4f}")
    
    return y_pred_proba

def apply_threshold(probabilities, threshold):
    """
    æ‡‰ç”¨é–¾å€¼å°‡æ©Ÿç‡è½‰æ›ç‚ºäºŒå…ƒé æ¸¬
    
    Parameters
    ----------
    probabilities : np.ndarray
        é æ¸¬æ©Ÿç‡
    threshold : float
        é–¾å€¼
    
    Returns
    -------
    np.ndarray
        äºŒå…ƒé æ¸¬çµæœ
    """
    predictions = (probabilities >= threshold).astype(int)
    return predictions

def create_submission_file(test_accounts, predictions, filename):
    """
    å»ºç«‹ç¬¦åˆæ¯”è³½æ ¼å¼çš„æäº¤æª”æ¡ˆ
    
    Parameters
    ----------
    test_accounts : np.ndarray
        æ¸¬è©¦é›†å¸³æˆ¶ID
    predictions : np.ndarray
        é æ¸¬çµæœ
    filename : str
        è¼¸å‡ºæª”æ¡ˆåç¨±
    
    Returns
    -------
    pd.DataFrame
        æäº¤è³‡æ–™æ¡†
    """
    submission_df = pd.DataFrame({
        'acct': test_accounts,
        'label': predictions
    })
    
    # å„²å­˜æª”æ¡ˆ
    submission_df.to_csv(filename, index=False)
    
    return submission_df

def analyze_threshold_results(probabilities, thresholds, total_accounts):
    """
    åˆ†æä¸åŒé–¾å€¼çš„é æ¸¬çµæœ
    
    Parameters
    ----------
    probabilities : np.ndarray
        é æ¸¬æ©Ÿç‡
    thresholds : list
        é–¾å€¼åˆ—è¡¨
    total_accounts : int
        ç¸½å¸³æˆ¶æ•¸
    
    Returns
    -------
    pd.DataFrame
        åˆ†æçµæœè³‡æ–™æ¡†
    """
    results = []
    
    for threshold in thresholds:
        predictions = apply_threshold(probabilities, threshold)
        alert_count = predictions.sum()
        alert_ratio = alert_count / total_accounts * 100
        
        results.append({
            'threshold': threshold,
            'alert_count': alert_count,
            'alert_ratio': alert_ratio,
            'normal_count': total_accounts - alert_count,
            'in_expected_range': EXPECTED_ALERT_RATIO_LOW <= alert_ratio <= EXPECTED_ALERT_RATIO_HIGH
        })
    
    return pd.DataFrame(results)

def recommend_threshold(analysis_df):
    """
    æ¨è–¦æœ€ä½³é–¾å€¼
    
    Parameters
    ----------
    analysis_df : pd.DataFrame
        é–¾å€¼åˆ†æçµæœ
    
    Returns
    -------
    float
        æ¨è–¦çš„é–¾å€¼
    """
    # å„ªå…ˆé¸æ“‡åœ¨é æœŸç¯„åœå…§çš„é–¾å€¼
    in_range = analysis_df[analysis_df['in_expected_range']]
    
    if not in_range.empty:
        # é¸æ“‡æœ€æ¥è¿‘ç¯„åœä¸­å¿ƒçš„é–¾å€¼
        target_ratio = (EXPECTED_ALERT_RATIO_LOW + EXPECTED_ALERT_RATIO_HIGH) / 2
        in_range['distance'] = abs(in_range['alert_ratio'] - target_ratio)
        best_threshold = in_range.loc[in_range['distance'].idxmin(), 'threshold']
    else:
        # å¦‚æœæ²’æœ‰åœ¨ç¯„åœå…§çš„ï¼Œé¸æ“‡æœ€æ¥è¿‘ä¸‹é™çš„
        analysis_df['distance'] = abs(analysis_df['alert_ratio'] - EXPECTED_ALERT_RATIO_LOW)
        best_threshold = analysis_df.loc[analysis_df['distance'].idxmin(), 'threshold']
    
    return best_threshold

def generate_predictions(model, X_test, test_accounts, thresholds=None):
    """
    ä¸»è¦çš„é æ¸¬ç”Ÿæˆå‡½æ•¸
    
    Parameters
    ----------
    model : object
        è¨“ç·´å¥½çš„æ¨¡å‹
    X_test : np.ndarray
        æ¸¬è©¦é›†ç‰¹å¾µçŸ©é™£
    test_accounts : np.ndarray
        æ¸¬è©¦é›†å¸³æˆ¶ID
    thresholds : list or None
        è¦æ¸¬è©¦çš„é–¾å€¼åˆ—è¡¨
    
    Returns
    -------
    list
        ç”Ÿæˆçš„æäº¤æª”æ¡ˆåˆ—è¡¨
    """
    print("\né–‹å§‹ç”Ÿæˆé æ¸¬...")
    print(f"  æ¸¬è©¦é›†å¤§å°ï¼š{len(X_test):,}")
    
    if thresholds is None:
        thresholds = DEFAULT_THRESHOLDS
    
    # ç”Ÿæˆé æ¸¬æ©Ÿç‡
    probabilities = predict_probabilities(model, X_test)
    
    # åˆ†æä¸åŒé–¾å€¼
    print("\n  åˆ†æä¸åŒé–¾å€¼çš„çµæœ...")
    analysis_df = analyze_threshold_results(probabilities, thresholds, len(test_accounts))
    
    print("\n    ã€é–¾å€¼åˆ†æçµæœã€‘")
    print("    " + "-"*70)
    print(f"    {'é–¾å€¼':^8} | {'é æ¸¬è­¦ç¤º':^10} | {'æ¯”ä¾‹(%)':^10} | {'æ˜¯å¦åœ¨é æœŸç¯„åœ':^15}")
    print("    " + "-"*70)
    
    submission_files = []
    
    for _, row in analysis_df.iterrows():
        threshold = row['threshold']
        alert_count = int(row['alert_count'])
        alert_ratio = row['alert_ratio']
        in_range = row['in_expected_range']
        
        # ç”Ÿæˆé æ¸¬
        predictions = apply_threshold(probabilities, threshold)
        
        # å»ºç«‹æª”å
        filename = f'submission_threshold_{int(threshold*100)}.csv'
        
        # å»ºç«‹æäº¤æª”æ¡ˆ
        create_submission_file(test_accounts, predictions, filename)
        submission_files.append(filename)
        
        # é¡¯ç¤ºçµæœ
        range_mark = "âœ“" if in_range else " "
        print(f"    {threshold:^8.2f} | {alert_count:^10d} | {alert_ratio:^10.2f} | {range_mark:^15}")
    
    print("    " + "-"*70)
    
    # æ¨è–¦æœ€ä½³é–¾å€¼
    best_threshold = recommend_threshold(analysis_df)
    print(f"\n  âœ… æ¨è–¦é–¾å€¼ï¼š{best_threshold:.2f}")
    
    best_row = analysis_df[analysis_df['threshold'] == best_threshold].iloc[0]
    print(f"     é æ¸¬è­¦ç¤ºæ•¸ï¼š{int(best_row['alert_count'])}")
    print(f"     é æ¸¬æ¯”ä¾‹ï¼š{best_row['alert_ratio']:.2f}%")
    
    # åŸºæ–¼æ­·å²è³‡æ–™çš„åˆ†æ
    print(f"\n  ğŸ“Š åƒè€ƒè³‡è¨Šï¼š")
    print(f"     æ­·å²è­¦ç¤ºæ¯”ä¾‹ï¼šç´„ 0.3% (1,004/333,768)")
    print(f"     é æœŸæ¸¬è©¦é›†è­¦ç¤ºæ¯”ä¾‹ï¼š{EXPECTED_ALERT_RATIO_LOW}-{EXPECTED_ALERT_RATIO_HIGH}%")
    print(f"     é æœŸè­¦ç¤ºå¸³æˆ¶æ•¸ï¼š{int(len(test_accounts)*EXPECTED_ALERT_RATIO_LOW/100)}-{int(len(test_accounts)*EXPECTED_ALERT_RATIO_HIGH/100)}")
    
    return submission_files

def load_predict_file():
    """
    è¼‰å…¥å¾…é æ¸¬å¸³æˆ¶æ¸…å–®
    
    Returns
    -------
    pd.DataFrame
        å¾…é æ¸¬å¸³æˆ¶è³‡æ–™æ¡†
    """
    predict_file = 'acct_predict.csv'
    
    if not os.path.exists(predict_file):
        raise FileNotFoundError(f"å¾…é æ¸¬æª”æ¡ˆä¸å­˜åœ¨ï¼š{predict_file}")
    
    df_predict = pd.read_csv(predict_file)
    df_predict['acct'] = df_predict['acct'].astype(str)
    
    return df_predict

if __name__ == "__main__":
    """
    ç¨ç«‹åŸ·è¡Œæ¸¬è©¦
    """
    print("="*80)
    print("æ¨¡å‹é æ¸¬æ¨¡çµ„ - ç¨ç«‹åŸ·è¡Œæ¨¡å¼")
    print("="*80)
    
    # éœ€è¦å…ˆåŸ·è¡Œå‰è™•ç†å’Œè¨“ç·´
    import sys
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    
    try:
        # è¼‰å…¥æ¨¡å‹
        model = load_model()
        
        # åŸ·è¡Œå‰è™•ç†ç²å–æ¸¬è©¦è³‡æ–™
        from Preprocess.data_preprocess import preprocess_data
        print("\nåŸ·è¡Œè³‡æ–™å‰è™•ç†...")
        X_train, y_train, X_test, test_accounts, feature_names = preprocess_data()
        
        # ç”Ÿæˆé æ¸¬
        submission_files = generate_predictions(model, X_test, test_accounts)
        
        print("\n" + "="*80)
        print("é æ¸¬å®Œæˆæ‘˜è¦")
        print("="*80)
        print(f"  ç”Ÿæˆæª”æ¡ˆæ•¸ï¼š{len(submission_files)}")
        print(f"  æª”æ¡ˆåˆ—è¡¨ï¼š")
        for file in submission_files:
            print(f"    - {file}")
        
        print(f"\n  å»ºè­°æäº¤é †åºï¼š")
        print(f"    1. submission_threshold_60.csv ï¼ˆæ¨è–¦ï¼‰")
        print(f"    2. submission_threshold_50.csv ï¼ˆåŸºæº–ï¼‰")
        print(f"    3. æ ¹æ“šåˆ†æ•¸èª¿æ•´é–¾å€¼")
        
    except FileNotFoundError as e:
        print(f"\nâŒ éŒ¯èª¤ï¼š{str(e)}")
        print(f"   è«‹å…ˆåŸ·è¡Œ model_train.py è¨“ç·´æ¨¡å‹")
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤ï¼š{str(e)}")
        import traceback
        traceback.print_exc()